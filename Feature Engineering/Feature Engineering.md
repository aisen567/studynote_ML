# [特征工程](https://www.zhihu.com/question/29316149/answer/607394337) [视频](https://www.youtube.com/watch?v=68ABAU_V8qI)

## 知识点

### 数据类型
在表格类数据建模过程中，常常需要处理的数据类型：
1. 文本_[python 字符串方法](https://zhuanlan.zhihu.com/p/80518649)
需要通过[正则表达式](https://www.cnblogs.com/shenjianping/p/11647473.html)，
做特征表示；[文本特征稀疏表示：词袋、ngram、tf-idf](https://zhuanlan.zhihu.com/p/42310942)
2. 类别变量
类别数量较少可直接onehot；  
类别数量较多可以尝试[均值编码](https://zhuanlan.zhihu.com/p/26308272)[等](https://github.com/scikit-learn-contrib/category_encoders)方案；  
lightgbm可以支持直接的[类别型特征](https://zhuanlan.zhihu.com/p/67475635)输入，xgb等其他模型需要onehot； 
3. 排序变量
一般可以按照连续性变量处理；
4. 连续变量
线性模型、逻辑回归,knn(涉及距离的模型)等需要进行标准化，缺失处理；
树模型不需要进行标准化，一般不需要处理缺失；

### 数据流程
一般在数据处理与特征工程的工作流程为：
1. 异常值处理；
2. [缺失值处理](https://zhuanlan.zhihu.com/p/137175585)；
3. 特征构造；
4. 分布调整与标准化  
在具体项目中，2，3，4可以调整顺序；

### 数据处理

[为什么要处理缺失](https://www.zhihu.com/question/58230411/answer/242037063)

数据标准化方法  
分布良好的数据可以直接进行中心标准化 (x - mu) / std  
有偏分布可以尝试做log等**非线性单调变换**后再进行**中心标准化** (x - mu) / std  
对于较为特殊的分布可以尝试RankGauss标准化；查看sklearn QuantileTransformer文档  

### 特征挖掘

特征越高阶，模型可以相对简单；特征越低阶，模型复杂度需要越高。 一句话结论：**寻找对label(click)区分度大且泛化能力较好的特征**。  
通过数据分析，可以统计出某个特征对样本标签的区分度，比如不同省份用户的点击率有明显差异，那么用户所在省份这个特征就有比较好的区分度。再举个反例，如果用“手机上是否装了微信”这个作为一个特征，预估某个点击率，由于绝大多数用户手机上都装了微信，因此这个特征没有区分度，很低效。那么，是不是特征对label的区分度越高越好呢？并不是。比如用户的id特征，可以完美区分出每个用户对不同物品的兴趣程度，但是用户id特征过于稀疏，往往无法充分地训练模型。
特征可以粗略地分为以下几类：
1. 基础属性特征，比如用户的年龄、性别、职业、地域等基础信息；物品的各级类目等基础属性.  
2. 统计类特征，用户过去不同时间窗口内对物品发生行为的统计，如点击/查看/下载/购买等；同样地，物品在不同时间窗口内的以上行为的统计.  
3. 上下文特征，如用户当前所处地理位置，当前时刻，当天是否为休息日，发薪日后几天等强时效性特征.  
4. 高阶交叉特征，两个独立特征交叉在一起的时候，往往会产生奇妙的化学反应，比如“用户所在地域”这个特征为美国，“时间”这个是特征为圣诞前夕，这两个特征组合起来，对“圣诞树”购买的几率就会大幅上升.  
5. 其他高级特征，如文本特征、图像特征等，用户的评论、签名，物品本身携带的文字内容信息，都携带了用户/物品的特性，通过BoW，Ngram，LDA软聚类，word2vec，fasttext等方式挖掘文本特征；另外，如果用户/物品带有图片，可以通过cnn将图片解析成向量，捕捉到图片特征.

优点：新构造的有效且合理的特征可提高模型的预测表现能力。  
缺点：新构造的特征不一定是对模型有正向影响作用的，也许对模型来说是没有影响的甚至是负向影响，拉低模型的性能。因此构造的新特征需要反复参与模型进行训练验证或者进行特征选择之后，才能确认特征是否是有意义的。

#### ***特征设计原理***

1. 新特征设计应与目标高度相关，要考虑的问题：
这个特征是否对目标有实际意义？
如果有用，这个特征重要性如何？
这个特征的信息是否在其他特征上体现过？

2. 新构建特征验证其有效性要考虑的问题：
需要领域知识、直觉、行业经验以及数学知识综合性考量特征的有效性，防止胡乱构造没有意义的特征。  
要反复与模型进行迭代验证其是否对模型有正向促进作用。  
或者进行特征选择判定新构建特征的重要性来衡量其有效性。  

#### ***特征构造常用方法***
特征构造需要不断结合具体业务情况做出合理分析，才能有根据性的构造出有用的新特征。

##### *++统计值构造法++*
通过统计单个或者多个变量的统计值(max,min,count,mean)等而形成新的特征。

1. 单变量  
如果某个特征与目标高度相关，那么可以根据具体的情况取这个特征的统计值作为新的特征。  
2. 多变量
如果特征与特征之间存在交互影响时，那么可以聚合分组两个或多个变量之后，再以统计值构造出新的特征。

举例
单变量：衣服颜色和你一样的小朋友**数量**作为新特征
多变量：衣服颜色和你一样的小朋友的**身高的平均值**作为新特征

##### *++连续数据离散化++*
有些时候我们需要对数据进行粗粒度、细粒度划分，以便模型更好的学习到特征的信息.
1. 粗粒度划分(连续数据离散化)：将年龄段0~100岁的连续数据进行粗粒度处理，也可称为二值化或离散化或分桶法

	2.1. 特征二值化  
  	设定一个划分的阈值，当数值大于设定的阈值时，就赋值为1；反之赋值为0。典型例子：划分年龄段  
	2.2. 无监督离散化  
  	分箱法：等宽(宽度)分箱法、等频(频数)分箱法 聚类划分：使用聚类算法将数据聚成几类，每一个类为一个划分  


2. 细粒度划分：在文本挖掘中，往往将段落或句子细分具体到一个词语或者字，这个过程称为细粒度划分

##### *++离散数据编码化++*
很多算法模型不能直接处理字符串数据，因此需要将类别型数据转换成数值型数据

1. 序号编码
  通常用来处理类别间具有大小关系的数据，比如成绩(高中低)
2. 独热编码
  (One-hot Encoding)通常用于处理类别间不具有大小关系的特征，比如血型(A型血、B型血、AB型血、O型血)， 独热编码会把血型变成一个稀疏向量，A型血表示为(1,0,0,0)，B型血表示为(0,1,0,0)， AB型血表示为(0,0,1,0)，O型血表示为(0,0,0,1)
3. 二进制编码
  二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。 以A、B、AB、O血型为例，A型血表示为00，B型血表示为01， AB型血表示为10，O型血表示为11

##### *++函数变换法++*
方法 简单常用的函数变换法(一般针对于连续数据)：平方(小数值—>大数值)、开平方(大数值—>小数值)、指数、对数、差分

例子  
对时间序列数据进行差分  
数据不呈正态分布时可运用  
当前特征数据不利于被模型捕获时  

### [特征选择](https://zhuanlan.zhihu.com/p/30404850)


[特征选择实战](https://zhuanlan.zhihu.com/p/32749489)  
[[阅读]特征工程概览](https://www.zhihu.com/question/28641663/answer/110165221)  
[[阅读]高阶特征工程](https://zhuanlan.zhihu.com/p/62773597)  
[顶级方案学习：kaggle-IEEE-Fraud-Prediction](https://github.com/azusakou/studynote_ML/blob/master/Feature%20Engineering/顶级方案学习：kaggle-IEEE-Fraud-Prediction.pdf)  

## QA
两个类别型变量构造笛卡尔特征组合为什么能提升模型表现？

(1)把特征通过运输到一个关系更简单的空间里面，比如说线性可分的空间就会提升，模型性能提高。  
(2)abc 3个变量，变量之间两两独立，但是变量与变量之间组成一个，就比如三个变量，是一个大的系统，就不是独立的了，所以说通过构造这个，比如说a和b的特征组合，那么这个特征组合对于预测变量是有效的，但是有可能这个a和b，这两个变量单独对于这个预测是没有什么效果的，这个时候需要去构造这样的一个特征组合
 
  
 
  
 
 
