# [特征工程](https://www.zhihu.com/question/29316149/answer/607394337) [视频](https://www.youtube.com/watch?v=68ABAU_V8qI)

## 知识点

### 数据类型
在表格类数据建模过程中，常常需要处理的数据类型：
1. 文本_[python 字符串方法](https://zhuanlan.zhihu.com/p/80518649)
需要通过[正则表达式](https://www.cnblogs.com/shenjianping/p/11647473.html)，
做特征表示；[文本特征稀疏表示：词袋、ngram、tf-idf](https://zhuanlan.zhihu.com/p/42310942)
2. 类别变量
类别数量较少可直接onehot；  
类别数量较多可以尝试[均值编码](https://zhuanlan.zhihu.com/p/26308272)[等](https://github.com/scikit-learn-contrib/category_encoders)方案；  
lightgbm可以支持直接的[类别型特征](https://zhuanlan.zhihu.com/p/67475635)输入，xgb等其他模型需要onehot； 
3. 排序变量
一般可以按照连续性变量处理；
4. 连续变量
线性模型、逻辑回归,knn(涉及距离的模型)等需要进行标准化，缺失处理；
树模型不需要进行标准化，一般不需要处理缺失；

### 数据流程
一般在数据处理与特征工程的工作流程为：
1. 异常值处理；
2. [缺失值处理](https://zhuanlan.zhihu.com/p/137175585)；
3. 特征构造；
4. 分布调整与标准化  
在具体项目中，2，3，4可以调整顺序；

### 数据处理

[为什么要处理缺失](https://www.zhihu.com/question/58230411/answer/242037063)

数据标准化方法  
分布良好的数据可以直接进行中心标准化 (x - mu) / std  
有偏分布可以尝试做log等**非线性单调变换**后再进行**中心标准化** (x - mu) / std  
对于较为特殊的分布可以尝试RankGauss标准化；查看sklearn QuantileTransformer文档  

### 特征挖掘

概念及工作原理概念：
特征构造主要是产生衍生变量，所谓衍生变量是指对原始数据进行加工、特征组合，生成有商业意义的新变量(新特征)  
优点：新构造的有效且合理的特征可提高模型的预测表现能力。  
缺点：新构造的特征不一定是对模型有正向影响作用的，也许对模型来说是没有影响的甚至是负向影响，拉低模型的性能。因此构造的新特征需要反复参与模型进行训练验证或者进行特征选择之后，才能确认特征是否是有意义的。
#### 特征设计原理
1. 新特征设计应与目标高度相关，要考虑的问题：
这个特征是否对目标有实际意义？
如果有用，这个特征重要性如何？
这个特征的信息是否在其他特征上体现过？

2. 新构建特征验证其有效性要考虑的问题：
需要领域知识、直觉、行业经验以及数学知识综合性考量特征的有效性，防止胡乱构造没有意义的特征。
要反复与模型进行迭代验证其是否对模型有正向促进作用。
或者进行特征选择判定新构建特征的重要性来衡量其有效性。

#### 特征构造常用方法
特征构造需要不断结合具体业务情况做出合理分析，才能有根据性的构造出有用的新特征。

##### 统计值构造法
通过统计单个或者多个变量的统计值(max,min,count,mean)等而形成新的特征。

1. 单变量  
如果某个特征与目标高度相关，那么可以根据具体的情况取这个特征的统计值作为新的特征。  
2. 多变量
如果特征与特征之间存在交互影响时，那么可以聚合分组两个或多个变量之后，再以统计值构造出新的特征。

举例
单变量：衣服颜色和你一样的小朋友**数量**作为新特征
多变量：衣服颜色和你一样的小朋友的**身高的平均值**作为新特征

##### 连续数据离散化
有些时候我们需要对数据进行粗粒度、细粒度划分，以便模型更好的学习到特征的信息.
1. 粗粒度划分(连续数据离散化)：将年龄段0~100岁的连续数据进行粗粒度处理，也可称为二值化或离散化或分桶法

2.1. 特征二值化  
  设定一个划分的阈值，当数值大于设定的阈值时，就赋值为1；反之赋值为0。典型例子：划分年龄段  
2.2. 无监督离散化  
  分箱法：等宽(宽度)分箱法、等频(频数)分箱法 聚类划分：使用聚类算法将数据聚成几类，每一个类为一个划分  


2. 细粒度划分：在文本挖掘中，往往将段落或句子细分具体到一个词语或者字，这个过程称为细粒度划分

##### 离散数据编码化
很多算法模型不能直接处理字符串数据，因此需要将类别型数据转换成数值型数据

1. 序号编码
  通常用来处理类别间具有大小关系的数据，比如成绩(高中低)
2. 独热编码
  (One-hot Encoding)通常用于处理类别间不具有大小关系的特征，比如血型(A型血、B型血、AB型血、O型血)， 独热编码会把血型变成一个稀疏向量，A型血表示为(1,0,0,0)，B型血表示为(0,1,0,0)， AB型血表示为(0,0,1,0)，O型血表示为(0,0,0,1)
3. 二进制编码
  二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。 以A、B、AB、O血型为例，A型血表示为00，B型血表示为01， AB型血表示为10，O型血表示为11










[CTR如何构造特征，Louis回答](https://www.zhihu.com/question/347715330/answer/849645828)  
[特征选择概览](https://zhuanlan.zhihu.com/p/30404850)  
[特征选择实战](https://zhuanlan.zhihu.com/p/32749489)  
[[阅读]特征工程概览](https://www.zhihu.com/question/28641663/answer/110165221)  
[[阅读]高阶特征工程](https://zhuanlan.zhihu.com/p/62773597)  
[顶级方案学习：kaggle-IEEE-Fraud-Prediction](https://github.com/azusakou/studynote_ML/blob/master/Feature%20Engineering/顶级方案学习：kaggle-IEEE-Fraud-Prediction.pdf)  

## QA
两个类别型变量构造笛卡尔特征组合为什么能提升模型表现？

(1)把特征通过运输到一个关系更简单的空间里面，比如说线性可分的空间就会提升，模型性能提高。  
(2)abc 3个变量，变量之间两两独立，但是变量与变量之间组成一个，就比如三个变量，是一个大的系统，就不是独立的了，所以说通过构造这个，比如说a和b的特征组合，那么这个特征组合对于预测变量是有效的，但是有可能这个a和b，这两个变量单独对于这个预测是没有什么效果的，这个时候需要去构造这样的一个特征组合
 
  
 
  
 
 
