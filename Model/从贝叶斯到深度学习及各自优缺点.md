[结构](https://static.coggle.it/diagram/WHeBqDIrJRk-kDDY/t/categories-of-algorithms-non-exhaustive)

# 正则化算法（Regularization Algorithms）
它是另一种方法（通常是回归方法）的拓展，这种方法会基于模型复杂性对其进行惩罚，它喜欢相对简单能够更好的泛化的模型。

1. 岭回归（Ridge Regression）
2. 最小绝对收缩与选择算子（LASSO）
3. GLASSO
4. 弹性网络（Elastic Net）
5. 最小角回归（Least-Angle Regression）

## 优点：
其惩罚会减少过拟合  
总会有解决方法  
## 缺点：
惩罚会造成欠拟合  
很难校准  

# 决策树算法（Decision Tree Algorithm）
决策树学习使用一个决策树作为一个预测模型，它将对一个 item（表征在分支上）观察所得映射成关于该 item 的目标值的结论（表征在叶子中）。树模型中的目标是可变的，可以采一组有限值，被称为分类树；在这些树结构中，叶子表示类标签，分支表示表征这些类标签的连接的特征。

ID3,C4.5,Caret tree

## 优点：
容易  
## 缺点：？？？？？

# 集成算法（Ensemble algorithms）
集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。

1. Boosting
2. Bootstrapped Aggregation（Bagging）
3. Stacking

## 优点：
当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多  
## 缺点：？？？？？






