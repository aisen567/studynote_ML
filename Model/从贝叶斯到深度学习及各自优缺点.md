[结构](https://static.coggle.it/diagram/WHeBqDIrJRk-kDDY/t/categories-of-algorithms-non-exhaustive)

# 正则化算法（Regularization Algorithms）
它是另一种方法（通常是回归方法）的拓展，这种方法会基于模型复杂性对其进行惩罚，它喜欢相对简单能够更好的泛化的模型。

1. 岭回归（Ridge Regression）
2. 最小绝对收缩与选择算子（LASSO）
3. GLASSO
4. 弹性网络（Elastic Net）
5. 最小角回归（Least-Angle Regression）

## 优点：
其惩罚会减少过拟合  
总会有解决方法  
## 缺点：
惩罚会造成欠拟合  
很难校准  

# 支持向量机（Support Vector Machines）
给定一组训练事例，其中每个事例都属于两个类别中的一个，支持向量机（SVM）训练算法可以在被输入新的事例后将其分类到两个类别中的一个，使自身成为非概率二进制线性分类器。SVM 模型将训练事例表示为空间中的点，它们被映射到一幅图中，由一条明确的、尽可能宽的间隔分开以区分两个类别。随后，新的示例会被映射到同一空间中，并基于它们落在间隔的哪一侧来预测它属于的类别。






# 决策树算法（Decision Tree Algorithm）
决策树学习使用一个决策树作为一个预测模型，它将对一个 item（表征在分支上）观察所得映射成关于该 item 的目标值的结论（表征在叶子中）。树模型中的目标是可变的，可以采一组有限值，被称为分类树；在这些树结构中，叶子表示类标签，分支表示表征这些类标签的连接的特征。

ID3,C4.5,Caret tree

## 优点：
容易解释，非线性，非参数型  
## 缺点：
容易过拟合，可能陷于局部最优

# 集成算法（Ensemble algorithms）
集成方法是由多个较弱的模型集成模型组，其中的模型可以单独进行训练，并且它们的预测能以某种方式结合起来去做出一个总体预测。

1. Boosting
2. Bootstrapped Aggregation（Bagging）
3. Stacking

## 优点：
当先最先进的预测几乎都使用了算法集成。它比使用单个模型预测出来的结果要精确的多  
## 缺点：？？？？？






