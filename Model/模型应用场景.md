[结构](https://static.coggle.it/diagram/WHeBqDIrJRk-kDDY/t/categories-of-algorithms-non-exhaustive)
[不同数据集上（121个），不同的分类器（179个）的实际效果](https://github.com/azusakou/studynote_ML/blob/master/Model/Do%20we%20Need%20Hundreds%20of%20Classifiers%20to%20Solve%20Real%20World%20Classification%20Problems%3F.pdf)
随机森林平均来说最强，但也只在9.9%的数据集上拿到了第一，优点是鲜有短板。  
SVM的平均水平紧随其后，在10.7%的数据集上拿到第一。  
神经网络（13.2%）和boosting（~9%）表现不错。  
数据维度越高，随机森林就比AdaBoost强越多，但是整体不及SVM[2]。  
数据量越大，神经网络就越强。  

# Nearest Neighbor
典型的例子是KNN，它的思路就是——对于待判断的点，找到离它最近的几个数据点，根据它们的类型决定待判断点的类型。它的特点是完全跟着数据走，没有数学模型可言。

适用情景：
需要一个特别容易解释的模型的时候。比如需要向用户解释原因的推荐算法。




