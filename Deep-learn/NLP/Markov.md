# 1.1 马尔科夫链（维基百科）

马尔可夫链（英语：Markov chain），又称离散时间马尔可夫链（discrete-time Markov chain，缩写为DTMC），因俄国数学家安德烈·马尔可夫得名，为状态空间中经过从一个状态到另一个状态的转换的随机过程。该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“无记忆性”称作马尔可夫性质。

 

# 1.2 马尔科夫过程——离散的叫马尔科夫链

在概率论及统计学中，马尔可夫过程（英语：Markov process）是一个具备了马尔可夫性质的随机过程，因为俄国数学家安德雷·马尔可夫得名。马尔可夫过程是不具备记忆特质的（memorylessness）。换言之，马尔可夫过程的条件概率仅仅与系统的当前状态相关，而与它的过去历史或未来状态，都是独立、不相关的。

具备离散状态的马尔可夫过程，通常被称为马尔可夫链。马尔可夫链通常使用离散的时间集合定义，又称离散时间马尔可夫链。有些学者虽然采用这个术语，但允许时间可以取连续的值。

 

# 1.3 隐马尔科夫模型定义

隐马尔可夫模型（Hidden Markov Model；缩写：HMM）或称作隐性马尔可夫模型，是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。

在正常的马尔可夫模型中，状态对于观察者来说是直接可见的。这样状态的转换概率便是全部的参数。而在隐马尔可夫模型中，状态并不是直接可见的，但受状态影响的某些变量则是可见的。每一个状态在可能输出的符号上都有一概率分布。因此输出符号的序列能够透露出状态序列的一些信息。

隐马尔科夫模型是关于时序的概率模型，描述一个由隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个可观测的观测随机序列的过程。

# 1.4 隐马尔科夫模型参数的确定

### 1.4.1 初始概率分布\pi

 i_1可能是状态1，状态2 ... 状态n，于是i_1就有个N点分布：

|i<sub>1</sub>|state 1|state 2|...|state n|
|----|----|----|----|----|
|*P*|P<sub>1</sub>|p<sub>2</sub>|...|p<sub>n</sub>|

即：i_1对应个n维的向量。
上面这个n维的向量就是初始概率分布，记做π。  

### 1.4.2 状态转移矩阵A
因为i_2和i_1不独立，所以i_2是状态1的概率有：i_1是状态1时i_2是状态1，i_1是状态2时i_2是状态1,..., i_1是状态n时i_2是状态1，如下表

|i<sub>2</sub>/i<sub>1</sub>|state 1|state 2|...|state n|
|----|----|----|----|----|
|state 1|P<sub>11</sub>|p<sub>12</sub>|...|p<sub>1n</sub>|
|state 2|P<sub>21</sub>|p<sub>22</sub>|...|p<sub>2n</sub>|
|...|...|...|...|...|
|state n|P<sub>n1</sub>|p<sub>n2</sub>|...|p<sub>nn</sub>|

即：i_1->i_2对应n*n的矩阵。  
同理：i_n -> i_{n+1}对应个n*n的矩阵。  
上面这些n*n的矩阵被称为状态转移矩阵，用An*n表示。  
当然了，真要说的话，i_n -> i_{n+1}的状态转移矩阵一定都不一样，但在实际应用中一般将这些状态转移矩阵定为同一个，即：只有一个状态转移矩阵。  

### 1.4.3 观测矩阵B

如果对于i_n有：状态1, 状态2, ..., 状态n，那i_n的每一个状态都会从下面的m个观测中产生一个：观测1, 观测2, ..., 观测m，所以有如下矩阵：

|i<sub>n</sub>/O<sub>m</sub>|Obs 1|Obs 2|...|Obs m|
|----|----|----|----|----|
|state 1|P<sub>11</sub>|p<sub>12</sub>|...|p<sub>1m</sub>|
|state 2|P<sub>21</sub>|p<sub>22</sub>|...|p<sub>2m</sub>|
|...|...|...|...|...|
|state n|P<sub>n1</sub>|p<sub>n2</sub>|...|p<sub>nm</sub>|

这可以用一个n*m的矩阵表示，也就是观测矩阵，记做Bn*m。

由于HMM用上面的π，A，B就可以描述了，于是我们就可以说：HMM由初始概率分布π、状态转移概率分布A以及观测概率分布B确定，为了方便表达，把A, B, π 用 λ 表示，即：

            λ = (A, B, π)

